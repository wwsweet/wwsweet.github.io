{"meta":{"title":"sweet","subtitle":null,"description":null,"author":"sweet","url":"http://yoursite.com"},"pages":[{"title":"tags","date":"2017-10-21T11:58:09.356Z","updated":"2017-10-21T11:58:09.356Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":"所有标签： python flask开发 心得 爬虫"},{"title":"","date":"2017-10-21T11:52:00.726Z","updated":"2017-10-21T11:51:47.643Z","comments":true,"path":"album/index.html","permalink":"http://yoursite.com/album/index.html","excerpt":"","text":""},{"title":"text","date":"2017-10-21T12:06:13.532Z","updated":"2017-10-21T12:06:13.532Z","comments":true,"path":"text/index.html","permalink":"http://yoursite.com/text/index.html","excerpt":"","text":"随笔： 随笔"}],"posts":[{"title":"数据库的增改查删","slug":"数据库的增改查删","date":"2017-10-21T09:33:02.000Z","updated":"2017-10-21T10:47:54.000Z","comments":true,"path":"2017/10/21/数据库的增改查删/","link":"","permalink":"http://yoursite.com/2017/10/21/数据库的增改查删/","excerpt":"数据库的增改查删","text":"数据库的增改查删 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748from flask import Flask, render_templatefrom flask_sqlalchemy import SQLAlchemyimport osbasedir = os.path.abspath(os.path.dirname(__file__))app = Flask(__name__)app.config['SQLALCHEMY_DATABASE_URI'] =\\'sqlite:///' + os.path.join(basedir, 'data.sqlite')app.config['SQLALCHEMY_COMMIT_ON_TEARDOWN'] = Truedb = SQLAlchemy(app)class Article(db.Model): __tablename__ = 'article' #Integer普通整数，一般是 32 位 #primary_key 如果设为 True ，这列就是表的主键 #autoincrement添加数据的时候自动加一 id = db.Column(db.Integer, primary_key=True, autoincrement=True) title = db.Column(db.String(100), nullable=False)#nullable：title不可以为空 content = db.Column(db.Text, nullable=False)db.create_all() #创建数据库#db.drop_all() 删除数据库@app.route('/')def hello_world(): #增加： article1 = Article(title = 'aaa', content = 'bbb') db.session.add(article1)#添加到会话中 db.session.commit()#提交到数据库 #查找 Article.query.all()#查找全部 result = Article.query.filter(Article.title == 'aaa').all()#filter为过滤器，查找名为aaa的数据 #result为列表(数组)，想要第一个数据则取result[0] #取第一个数据的时候也可以result = Article.query.filter(Article.title == 'aaa').first（） #改 article1.title = 'new title' db.session.commit() # 提交到数据库 #删除 result = Article.query.filter(Article.content == 'bbb').first() db.session.delete(result) return 'Hello World!'if __name__ == '__main__': app.run()","categories":[],"tags":[{"name":"flask开发","slug":"flask开发","permalink":"http://yoursite.com/tags/flask开发/"}]},{"title":"爬虫实战之中工校网新闻","slug":"爬虫实战之中工校网新闻","date":"2017-07-23T05:55:11.000Z","updated":"2017-10-21T11:00:47.152Z","comments":true,"path":"2017/07/23/爬虫实战之中工校网新闻/","link":"","permalink":"http://yoursite.com/2017/07/23/爬虫实战之中工校网新闻/","excerpt":"以下的小程序是爬取中工校网标题：","text":"以下的小程序是爬取中工校网标题：首先，通过分析中工校网新闻的URL发现，http://www.zzti.edu.cn/info/1041/19593.htm最后的19593控制这页数。然后，构建URL，获取想要的新闻信息123456789101112131415161718192021222324252627import urllib.requestimport urllib.errorimport reimport timewhile True: page = input('请输入要寻找的新闻页数（小于19596）输入‘q’退出：') if page == 'q': break url = 'http://www.zzti.edu.cn/info/1041/' + str(page) + '.htm' try: req = urllib.request.urlopen(url) html = req.read().decode('utf-8') pattern = re.compile('&lt;td class=\"titles.*?&gt;(.*?)&lt;/td&gt;.*?&lt;div id=\"vsb_content_500\"&gt;(.*?)&lt;/div&gt;.*?&lt;/div&gt;.*?&lt;/td&gt;', re.S) items = re.findall(pattern, html) for item in items: print (item[0], item[1]) except urllib.error.URLError as e: if hasattr(e, 'code'): print(e.code) if hasattr(e, 'reason'): print(e.reason) time.sleep(1) items = re.findall(pattern, html) == items = pattern.findall(html) 正则表达式中，“.”的作用是匹配除“\\n”以外的任何字符，也就是说，它是在一行中进行匹配。这里的“行”是以“\\n”进行区分的。a字符串有每行的末尾有一个“\\n”，不过它不可见。 如果不使用re.S参数，则只在每一行内进行匹配，如果一行没有，就换下一行重新开始，不会跨行。而使用re.S参数以后，正则表达式会将这个字符串作为一个整体，将“\\n”当做一个普通的字符加入到这个字符串中，在整体中进行匹配。","categories":[],"tags":[{"name":"爬虫","slug":"爬虫","permalink":"http://yoursite.com/tags/爬虫/"}]},{"title":"爬虫实战一之糗事百科","slug":"爬虫实战一之糗事百科","date":"2017-07-23T05:54:17.000Z","updated":"2017-10-21T11:00:55.632Z","comments":true,"path":"2017/07/23/爬虫实战一之糗事百科/","link":"","permalink":"http://yoursite.com/2017/07/23/爬虫实战一之糗事百科/","excerpt":"目标：（1）抓取糗事百科热门段子（2）过滤带有图片的段子（3）实现显示一个段子的发布时间，发布人，段子内容，点赞数","text":"目标：（1）抓取糗事百科热门段子（2）过滤带有图片的段子（3）实现显示一个段子的发布时间，发布人，段子内容，点赞数 确定URL并抓取页面代码：先用最简单的代码来实现抓取看看能不能成功12345678910111213141516import urllib.requestimport urllib.errorimport repage = 2url = 'https://www.qiushibaike.com/8hr/page/' + str(page) + '/?s=5002335'try: request=urllib.request.Request(url) response=urllib.request.urlopen(request) print(response.read())except urllib.error.URLError as e: if hasattr(e, 'code'): print(e.code) if hasattr(e, 'reason'): print(e.reason) 运行结果：raise RemoteDisconnected(“Remote end closed connection without”http.client.RemoteDisconnected: Remote end closed connection without response结果分析：应该是headers验证的问题，加上一个headers验证试试看;1234567891011121314151617import urllib.requestimport urllib.errorimport repage = 2url = 'https://www.qiushibaike.com/8hr/page/' + str(page) + '/?s=5002335'try: req = urllib.request.Request(url) req.add_header('User-Agent', 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36') response = urllib.request.urlopen(req) print(response.read())except urllib.error.URLError as e: if hasattr(e, 'code'): print(e.code) if hasattr(e, 'reason'): print(e.reason) 运行结果：打印出了第二页的HTML代码 提取某一页的所有段子：(并过滤图片代码）123456789101112131415161718192021222324import urllib.requestimport urllib.errorimport repage = 2url = 'https://www.qiushibaike.com/8hr/page/' + str(page) + '/?s=5002335'try: req = urllib.request.Request(url) req.add_header('User-Agent', 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36') response = urllib.request.urlopen(req) content = response.read().decode('utf-8') pattern = re.compile('title=.*?&lt;h2&gt;(.*?)&lt;/h2&gt;.*?&lt;span&gt;(.*?)&lt;/span&gt;.*?&lt;/a&gt;(.*?)&lt;div class=\"stats\"&gt;.*?class=\"number\"&gt;(.*?)&lt;/i&gt;',re.S) items = re.findall(pattern, content) for item in items: haveImg = re.search('img',item[2]) if not haveImg: print (item[0]+'\\n'+item [1]+'\\n'+item [3]) except urllib.error.URLError as e: if hasattr(e, 'code'): print(e.code) if hasattr(e, 'reason'): print(e.reason) 正则表达式分析：（1）（.?）代表一个分组，在这个正则表达式中，我匹配了三个分组，在后面的遍历item中，item[0]就代表第一个（.?）代表的内容，以此类推。（2）re.S表示在匹配时为点任意模式，点也可以表示换行符。 我们可以发现，带有图片的段子会有类似img的代码，而不带图片的则没有，所以，我们的正则表达式的item[2]就是获取了图片的内容，如果不带图片，item[2]获取的内容就是空。 http://blog.csdn.net/finna_xu/article/details/68070662","categories":[],"tags":[{"name":"爬虫","slug":"爬虫","permalink":"http://yoursite.com/tags/爬虫/"}]},{"title":"正则表达式","slug":"正则表达式","date":"2017-07-21T05:55:58.000Z","updated":"2017-10-21T10:59:18.052Z","comments":true,"path":"2017/07/21/正则表达式/","link":"","permalink":"http://yoursite.com/2017/07/21/正则表达式/","excerpt":"正则表达式通常被用来检索、替换那些匹配某个模式的文本。正则表达式困难的不是匹配到想要的内容，而是尽可能的不匹配到不想要的内容","text":"正则表达式通常被用来检索、替换那些匹配某个模式的文本。正则表达式困难的不是匹配到想要的内容，而是尽可能的不匹配到不想要的内容 概念：正则表达式是对字符串操作的一种逻辑公式，就是用事先定义好的一些特定字符、及这些特定字符的组合，组成一个“规则字符串”，这个“规则字符串”用来表达对字符串的一种过滤逻辑。特点： 灵活性、逻辑性和功能性非常的强； 可以迅速地用极简单的方式达到字符串的复杂控制。 首先要明白以下几个函数的意思： re.compile(pattern,flag)根据正则匹配字符串以及附加条件，返回一个pattern对象 re.search(pattern,string)搜索整个字符串，知道发现符合正则表达式的字符串 re.match(pattern,string)从头开始检测字符串是否符合正则表达式，必须从字符串的第一个字符开始 re.findall(pattern,string)根据正则表达式分割字符串，将找到的所有结果放到list中返回 查找字符串：1234567import rekey = r\"saas and sas and saaas\"p1 = r\"sa&#123;1,3&#125;s\"pattern1 = re.compile(p1)print(pattern1.findall(key)) p1 = r&quot;sa{1,3}s&quot;表达的意思是a最少重复一次，最多重复三次。 查找邮件地址：123456789import rekey = r\"ben@forta.com \" \\ r\"ben.forta@forta.com \" \\ r\"ben@urgent.forta.com\"p1 = r\"\\w+[\\w.]*@[\\w.]+\\w+\"pattern1 = re.compile(p1)print(pattern1.findall(key)) 文本匹配：（‘+’和‘*’的贪婪型，‘?’变惰型）1234567import rekey = r\"T living in &lt;B&gt;AK&lt;/B&gt; and hahaj and &lt;b&gt;HI&lt;/b&gt;\"p1 = r\"&lt;[Bb]&gt;.+&lt;/[Bb]&gt;\"pattern1 = re.compile(p1)print(pattern1.findall(key)) 上面的运行结果是：[&#39;&lt;B&gt;AK&lt;/B&gt; and hahaj and &lt;b&gt;HI&lt;/b&gt;&#39;]为什么呢？因为+是贪婪型的，它会尽可能匹配到更多的字符。那么解决这一问题就需要在+后面添加一个字符?将贪婪型变为惰型即为：p1 = r&quot;&lt;[Bb]&gt;.+&lt;/[Bb]&gt;&quot;这样就可以获得想要的结果了。 向前向后查找：假如得到一个网页的HTML源码，其中有一段&lt;html&gt;&lt;body&gt;&lt;h1&gt;hello world&lt;h1&gt;&lt;/body&gt;&lt;/html&gt;想要把hello word提取出来，可这样写：12345678import rekey=r\"&lt;html&gt;&lt;body&gt;&lt;h1&gt;hello world&lt;h1&gt;&lt;/body&gt;&lt;/html&gt;\"#要匹配的文本p1=r\"(?&lt;=&lt;h1&gt;).+?(?=&lt;h1&gt;)\"#正则表达式pattern1=re.compile(p1)#编译这段正则表达式matcher1=re.search(pattern1,key)#在源文本中搜索符合正则表达式的部分print(matcher1.group(0))#输出 p1 = r&quot;(?&lt;=&lt;h1&gt;).+?(?=&lt;h1&gt;)&quot;看到(?&lt;=&lt;h1&gt;)和 (?=&lt;h1&gt;)了吗？第一个?&lt;=表示在被匹配字符前必须得有&lt;h1&gt;，后面的?=表示被匹配字符后必须有&lt;h1&gt;。简单来说，就是你要匹配的字符是XX，但必须满足形式是AXXB这样的字符串，那么你就可以这样写正则表达式p = r&quot;(?&lt;=A)XX(?=B)&quot;匹配到的字符串就是XX。并且，向前查找向后查找不需要必须同时出现。如果你愿意，可以只写满足一个条件。所以你也不需要记住哪个是向前查找，哪个是向后查找。只要记住?&lt;=后面跟着的是前缀要求，?=后面跟的是后缀要求。 回溯引用：123456789import rekey = r\"&lt;H1&gt;welcome&lt;/H1&gt;\" \\ r\"and &lt;H2&gt;happy&lt;/H3&gt;\" \\ r\"and &lt;H3&gt;wireless&lt;/H3&gt;\"p1 = r\"&lt;[Hh][1-6]&gt;.*?&lt;/[Hh][1-6]&gt;\"pattern1 = re.compile(p1)print(pattern1.findall(key)) 原本要匹配&lt;h1&gt;&lt;/h1&gt;之间的内容，现在知道HTML有多级标题，想把每一级的标题内容都提取出来:p1 = r&quot;&lt;[Hh][1-6]&gt;.*?&lt;/[Hh][1-6]&gt;&quot;这样一来，你就可以将HTML页面内所有的标题内容全部匹配出来。但是，同时也把不符合标题的格式也匹配出来了，例如：&lt;H2&gt;happy&lt;/H3&gt;如若把后面的[1-6]改为\\1或者1,2,3...则能筛选出需要的标题 查找IP地址：1234567import rekey = r\"127.0.0.1 and\"p1 = r\"(((\\d&#123;1,2&#125;)|(1\\d&#123;2&#125;)|(2[0-4]\\d)|(25[0-5]))\\.)&#123;3&#125;\" \\ r\"((\\d&#123;1,2&#125;)|(1\\d&#123;2&#125;)|(2[0-4]\\d)|(25[0-5]))\"pattern1 = re.compile(p1)print(re.search(p1,key)) 以上都是较常用的例子，看完《正则表达式必知必会》写了以上的内容，很多内容都没有写，以后继续补充。","categories":[],"tags":[{"name":"爬虫","slug":"爬虫","permalink":"http://yoursite.com/tags/爬虫/"}]},{"title":"一个简单的爬虫抓取图片程序","slug":"一个简单的爬虫抓取图片程序","date":"2017-07-21T02:44:48.000Z","updated":"2017-10-21T10:59:35.513Z","comments":true,"path":"2017/07/21/一个简单的爬虫抓取图片程序/","link":"","permalink":"http://yoursite.com/2017/07/21/一个简单的爬虫抓取图片程序/","excerpt":"一个简单的爬虫抓取图片小程序，能够快速获取大量图片，并将图片保存至指定文件夹，省去了一个一个下载图片的麻烦。","text":"一个简单的爬虫抓取图片小程序，能够快速获取大量图片，并将图片保存至指定文件夹，省去了一个一个下载图片的麻烦。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677import urllib.requestimport osimport random #使用代理IP是用到此模块def url_open(url): req=urllib.request.Request(url) #为请求设置user-agent,使得程序看起来更像一个人类 req.add_header('User-Agent','Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36') #代理IP，使用户能以不同IP访问，从而防止被服务器发现 '''iplist=['1.193.162.123:8000', '1.193.162.91:8000', '1.193.163.32:8000'] proxy_support = urllib.request.ProxyHandler(&#123;'http':random.choice(iplist)&#125;) opener = urllib.request.build_opener(proxy_support) opener.addheaders = [('User-Agent', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.154 Safari/537.36 LBBROWSER')] urllib.request.install_opener(opener)''' response = urllib.request.urlopen(req) html = response.read() return htmldef get_page(url): html = url_open(url).decode('utf-8') a = html.find('current-comment-page')+23 b = html.find(']',a) #print(html[a:b]) return html[a:b]def find_imgs(url): html = url_open(url).decode('utf-8') img_addrs = [] a=html.find('img src=') while a!=-1: b=html.find('.jpg', a, a+140) if b != -1: if html[a+9] != 'h': img_addrs.append('http:'+html[a+9:b+4]) else: img_addrs.append(html[a+9:b+4]) else: b = a + 9 a = html.find('img src=', b) return img_addrsdef save_imgs(folder,img_addrs): for each in img_addrs: filename = each.split('/')[-1] with open(filename,'wb') as f: img = url_open(each) f.write(img)#主函数：def down(folder='net',pages=10): os.mkdir(folder) #创建目录 os.chdir(folder) #修改目录途径 url = \"http://jandan.net/pic/\" page_num = int(get_page(url)) for i in range(pages): page_num -= 1 page_url = url + 'page-' + str(page_num) + '#comments' img_addrs = find_imgs(page_url) save_imgs(folder, img_addrs)if __name__ == '__main__': down()","categories":[],"tags":[{"name":"爬虫","slug":"爬虫","permalink":"http://yoursite.com/tags/爬虫/"}]},{"title":"使用urllib访问网页","slug":"使用urllib访问网页","date":"2017-07-21T01:55:24.000Z","updated":"2017-10-21T11:00:38.298Z","comments":true,"path":"2017/07/21/使用urllib访问网页/","link":"","permalink":"http://yoursite.com/2017/07/21/使用urllib访问网页/","excerpt":"urllib.request是一个用于访问URL的Python模块，urlopen函数可以访问不同协议的URL。 一个简单的读取URL信息的代码","text":"urllib.request是一个用于访问URL的Python模块，urlopen函数可以访问不同协议的URL。 一个简单的读取URL信息的代码 123456import urllib.requestresponse = urllib.request.urlopen(\"http://www.fishc.com\") #打开网页html = response.read() #读取URL信息 是二进制字符串html = html.decode(\"utf-8\") #解码操作print(html) 下载一个图片并保存123456import urllib.requestresponse = urllib.request.urlopen('https://ss2.baidu.com/73Z1bjeh1BF3odCf/it/u=2991169923,1001222125&amp;fm=202')aa = response.read()with open('ss.jpg', 'wb') as f: f.write(aa) 123456789101112131415161718192021222324=================== RESTART: C:\\Users\\dell\\Desktop\\dad.py ===================&gt;&gt;&gt; response.geturl()'https://ss2.baidu.com/73Z1bjeh1BF3odCf/it/u=2991169923,1001222125&amp;fm=202'&gt;&gt;&gt; response.info()&lt;http.client.HTTPMessage object at 0x04340430&gt;&gt;&gt;&gt; print(response.info())Server: bfe/1.0.8.13-sslpool-patchDate: Fri, 21 Jul 2017 03:20:48 GMTContent-Type: image/jpegContent-Length: 2876Connection: closeETag: 0ba505cffa84a3ec5ff73df2ba148aefLast-Modified: Thu, 01 Jan 1970 00:00:00 GMTExpires: Tue, 08 Aug 2017 00:55:09 GMTAge: 658546Cache-Control: max-age=2628000Accept-Ranges: bytesAccess-Control-Allow-Origin: *Ohc-Response-Time: 1 0 0 0 0 0Timing-Allow-Origin: http://www.baidu.com&gt;&gt;&gt; response.getcode()200 response.geturl() 是获取图片地址信息的response.info() 是http manage对象print(response.info()) 打印对象response.getcode() 获取对象状态 利用有道词典来翻译文本：Get是向服务器索取数据的一种请求，而Post是向服务器提交数据的一种请求。 隐藏访问用header urlparse负责解析功能 encode(&#39;utf-8&#39;)是将utf-8的形式转化为其他形式decode(&#39;utf-8&#39;)是将其他形式转化为utf-812345678910111213141516171819202122232425262728293031323334import urllib.requestimport urllib.parseimport jsonimport timewhile True: content = input(\"请输入要翻译的内容(输入q，退出:\") if content == 'q': break url='http://fanyi.youdao.com/translate?smartresult=dict&amp;smartresult=rule&amp;smartresult=ugc' data=&#123;&#125; data['type'] = 'AUTO' data['i'] = content data['doctype'] = 'json' data['xmlversion'] = '2.1' data['keyfrom'] = 'fanyi.web' data['ue'] = 'UTF-8' data['action'] = 'FY_BY_CL1CKBUTTON' data['typoResult'] = 'true' data = urllib.parse.urlencode(data).encode('utf-8')#编码成URL格式，所以用到模板urllib.parse req = urllib.request.Request(url,data) req.add_header('User-Agent','Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.108 Safari/537.36 2345Explorer/8.6.2.15784') response = urllib.request.urlopen(req) html = response.read().decode('utf-8') target = json.loads(html) #将html的值传给terget target = target['translateResult'][0][0]['tgt'] print(target) time.sleep(5) #下次循环时间间隔为5秒 通过json.loads(html)可以看到html字典里的内容，将html的值传给terget 修改header有两种方法：1.通过Request的headers参数修改：123req = urllib.request.Request(url, data, head)head = &#123;&#125;head['User-Agent'] = 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.108 Safari/537.36 2345Explorer/8.6.2.15784' 2.通过Request.add_header()方法修改：12req = urllib.request.Request(url, data)req.add_header('User-Agent', 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.108 Safari/537.36 2345Explorer/8.6.2.15784') 头信息：我们在这里讨论一个特殊的HTTP头信息，来说明如何在你的HTTP请求中添加头信息。 一些网站不喜欢被程序访问，或者会给不同的浏览器发送不同的版本。默认情况下，urllib会把自身标记为Python-urllib/x.y(其中x和y表示Python的版本号，如Python-urllib/2.5)，这可能会迷惑网站，或者干脆不起作用。浏览器标识自己的方式就是通过User-agent头信息。当你创建一个Request对象时，你可以传递一个头信息的字典。下面的例子发起的是跟上面一样的请求，但是把自己标识为一个IE浏览器的版本。1234567891011121314151617import urllib.parseimport urllib.requesturl = 'http://www.someserver.com/cgi-bin/register.cgi'user_agent = 'Mozilla/5.0 (Windows NT 6.1; Win64; x64)'data = &#123;'name':'Michael Foord', 'location':'Northampton', 'language':'Python' &#125;data = urllib.parse.urlencode(data).encode('ascii')req = urllib.request.Request(url, data)req.add_header('User-Agent', user_agent)response = urllib.request.urlopen(req)html = response.read()print(html) 处理异常：urlopen在不能处理某个响应的时候会抛出URLError(虽然一般使用Python API时，ValueError、TypeError等内建异常也可能被抛出)。HTTPError是URLError的子类，在遇到HTTP URL的特殊情况时被抛出。异常类出自urllib.error模块。 URLError:一般来说，URLError被抛出是因为没有网络连接(没有到指定服务器的路径)，或者是指定服务器不存在。在这种情况下，抛出的异常将会包含一个‘reason’属性，这是包含一个错误码和一段错误信息的元组。 HTTPError:每一个来自服务器的HTTP响应都包含一个数字的“状态码”。有时状态码表明服务器不能执行请求。默认的处理程序会为你处理其中的部分响应(比如，如果响应是“重定向”，要求客户端从一个不同的URL中获取资料，那么urllib将会为你处理这个)。对于那些不能处理的响应，urlopen将会抛出一个HTTPError。典型的错误包括‘404’(页面未找到)，‘403’(请求禁止)，和‘401’(请求认证)。抛出的HTTPError实例有一个整型的‘code’属性，对应于服务器发送的错误。 如果希望程序对HTTPError和URLError有所准备,则可以这样写代码：123456789101112131415import urllib.requestimport urllib.errorreq = urllib.request.Request('http://www.pretend_server.org')try: response = urllib.request.urlopen(req)except urllib.error.URLError as e: if hasattr(e, 'reason'): print('We failed to reach a server.') print('Reason: ', e.reason) elif hasattr(e, 'code'): print('The server couldn\\'t fulfill the request.') print('Error code: ', e.code) else: pass","categories":[],"tags":[{"name":"爬虫","slug":"爬虫","permalink":"http://yoursite.com/tags/爬虫/"}]},{"title":"文件IO","slug":"文件IO","date":"2017-07-15T06:32:23.000Z","updated":"2017-10-21T11:00:16.420Z","comments":true,"path":"2017/07/15/文件IO/","link":"","permalink":"http://yoursite.com/2017/07/15/文件IO/","excerpt":"文本文件：打开文件：","text":"文本文件：打开文件：123f = open('D:/sss.txt', 'r')print(f.read())f.close() 用with语句打开文件：12with open('D:/sss.txt', 'r') as f: print(f.read()) 要读取非UTF-8编码的文本文件，需要给 open() 函数传入 encoding 参数例如，读取 GBK 编码的文件：12f = open('/Users/michael/gbk.txt', 'r', encoding='gbk', errors='ignore')print(f.read()) 二进制文件（图片视频）：读文件：12f = open('/Users/michael/test.jpg', 'rb')print(f.read()) 写文件：12with open('/Users/michael/test.txt', 'w') as f: f.write('Hello, world!') StringIO和BytesIOStringIO操作的只能是str，如果要操作二进制数据，就需要使用BytesIO 读取StringIO ：1234567891011from io import StringIOf = StringIO('Hello!\\nHi!\\nGoodbye!')while True: s = f.readline() if s == '': break print(s.strip())输出结果：Hello!Hi!Goodbye! 写文件：123456789101112from io import StringIOf = StringIO()print(f.write('hello'))print(f.write(' '))print(f.write('world!'))print(f.getvalue())输出：516hello world! BytesIO12345678from io import BytesIOf = BytesIO()print(f.write('中文'.encode('utf-8')))print(f.getvalue())输出：6b'\\xe4\\xb8\\xad\\xe6\\x96\\x87' 操作文件和目录：os模块12import osprint(os.name) #操作类型 1.获取详细的系统信息，可以调用 uname() 函数：print(os.uname()) 2.操作系统中定义的环境变量，全部保存在 os.environ 这个变量中，可以直接查看：print(os.environ) 3.要获取某个环境变量的值，可以调用print(os.environ.get(&#39;PATH&#39;)) 4.查看当前目录的绝对路径:print( os.path.abspath(&#39;.&#39;)) 5.把一个路径拆分为两部分，后一部分总 是最后级别的目录或文件名：print( os.path.split(&#39;/Users/michael/testdir/file.txt&#39;)) 6.直接得到文件扩展名print(os.path.splitext(&#39;/path/to/file.txt&#39;)) 7.对文件重命名:os.rename(&#39;test.txt&#39;, &#39;test.py&#39;) 8.删掉文件: os.remove(&#39;test.py&#39;) 9.要列出当前目 录下的所有目录:[x for x in os.listdir(&#39;.&#39;) if os.path.isdir(x)] 10.要列出所有的 .py 文件:[x for x in os.listdir(&#39;.&#39;) if os.path.isfile(x) and os.path.splitext(x)[1]==&#39;.py&#39;]","categories":[],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"端口扫描","slug":"端口扫描","date":"2017-07-13T06:42:04.000Z","updated":"2017-10-21T11:01:05.271Z","comments":true,"path":"2017/07/13/端口扫描/","link":"","permalink":"http://yoursite.com/2017/07/13/端口扫描/","excerpt":"简单的端口扫描器代码：","text":"简单的端口扫描器代码： 123456789101112131415161718192021222324#!/usr/bin/env python# -*- coding: utf-8 -*-import sysfrom socket import *host = sys.argv[1] #读取端口及目标服务器ports = sys.argv[2].split('-')start_port = int(ports[0]) #传递端口的范围end_port = int(ports[1])target_ip = gethostbyname(host) #传递目标IP地址opened_ports = [] #测试TCP端口连接for port in range(start_port, end_port): sock = socket(AF_INET, SOCK_STREAM) #IPv4,TCP连接 sock.settimeout(10) result = sock.connec_ex(target_ip, port) if result == 0: opened_ports.append(port)print('Opened poers:')for i in opened_ports: #输出端口开放结果 print(i) 然后用命令行的方式进行传参python wsw.py 127.0.0.1 100-200先用命令行进入wsw.py文件所在的文件，再执行上方代码。 AF_INET（又称 PF_INET）是 IPv4 网络协议的套接字类型，AF_INET6则是IPv6 的；而 AF_UNIX 则是 Unix 系统本地通信。选择 AF_INET 的目的就是使用 IPv4 进行通信。因为 IPv4 使用 32 位地址，相比IPv6 的 128 位来说，计算更快，便于用于局域网通信。而且 AF_INET 相比 AF_UNIX 更具通用性，因为 Windows 上有 AF_INET 而没有 AF_UNIX。 SOCK_STREAM：TCP是连接的，提供序列化的，可靠的，双向连接的字节流。支持带外数据传输 多线程端口扫描代码：123456789101112131415161718192021222324252627# -*- coding: utf-8 -*-import sysimport threadingfrom socket import *print('dsjfhdj')def tcp_test(port): sock = socket(AF_INET, SOCK_STREAM) sock.settimeout(10) result = sock.connect_ex((target_ip, port)) if result == 0: lock.acquire() #加锁 print(\"Opened Port:\",port) lock.release() #释放锁if __name__=='__main__': host = sys.argv[1] portstrs = sys.argv[2].split('-') start_port = int(portstrs[0]) end_port = int(portstrs[1]) target_ip = gethostbyname(host) lock = threading.Lock() for port in range(start_port, end_port): threading.Thread(target = tcp_test, args = (port,)) ading.Thread(target = tcp_test, args = (port,)) 用来创建一个线程，该函数的第一个参数是一个线程中执行的函数，第二个参数必须是个元组，作为函数的输入，由于 tcp_test 函数只有一个参数，所以我们使用(port,)这种形式表示这个参数为元组。 实现TCP测试函数，需要注意print输出时候需要加锁，如果不加锁可能会出现多个输出混合在一起的错误状态，而锁需要在程序启动时创建，从而能让新建的线程共享这个锁， 注意当输出执行完后要释放锁lock。 端口扫描： http://www.yukaige.com/?p=160 创建服务端和客户端：代码详解：http://www.cnblogs.com/kellyseeme/p/5525026.html python socket编程详细介绍：http://blog.csdn.net/rebelqsp/article/details/22109925","categories":[],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"python中的模块","slug":"python中的模块","date":"2017-07-12T07:43:49.000Z","updated":"2017-10-21T10:57:21.419Z","comments":true,"path":"2017/07/12/python中的模块/","link":"","permalink":"http://yoursite.com/2017/07/12/python中的模块/","excerpt":"","text":"什么是模块，模块应该如何使用，见连接：http://www.cnblogs.com/dolphin0520/archive/2013/03/19/2969152.html from math import *是一次性引入math中所有的东西。 后续学到模块的新东西再继续添加","categories":[],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"Python 多线程","slug":"Python-多线程","date":"2017-07-11T05:50:01.000Z","updated":"2017-10-21T10:57:03.351Z","comments":true,"path":"2017/07/11/Python-多线程/","link":"","permalink":"http://yoursite.com/2017/07/11/Python-多线程/","excerpt":"通过看博客才明白什么是单线程和多线程，它们又是如何实现的等等问题，感觉这篇文章写的特别通俗易懂，记录一下。不过作者在文章中间出现了一些问题123456if __name__ == '__main__': for t in threads: t.setDaemon(True) t.start() t.join()print \"all over %s\" %ctime()","text":"通过看博客才明白什么是单线程和多线程，它们又是如何实现的等等问题，感觉这篇文章写的特别通俗易懂，记录一下。不过作者在文章中间出现了一些问题123456if __name__ == '__main__': for t in threads: t.setDaemon(True) t.start() t.join()print \"all over %s\" %ctime() 虽然解决了主线程的结束导致子线程的结束，但是如果前面的进程执行速度较慢，后面的进程执行速度快，但是只有最后一个进程设置了t.join（），会导致前面的进程被主线程终止。例如：把music中sleep（7）休眠时间改为大于5，此问题就暴露出来了，当t2线程结束之后，程序结束，但是t1进程还没有执行完毕，这明显与我们的初衷不符。所以建议改成12for t in threads： t.join() 便可避免此问题","categories":[],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"python strip()函数 以及 yield","slug":"python-strip-函数","date":"2017-07-09T09:37:19.000Z","updated":"2017-10-21T10:55:51.360Z","comments":true,"path":"2017/07/09/python-strip-函数/","link":"","permalink":"http://yoursite.com/2017/07/09/python-strip-函数/","excerpt":"python strip()函数声明：s为字符串，rm为要删除的字符序列 s.strip(rm) 删除s字符串中开头、结尾处，位于 rm删除序列的字符 s.lstrip(rm) 删除s字符串中开头处，位于 rm删除序列的字符","text":"python strip()函数声明：s为字符串，rm为要删除的字符序列 s.strip(rm) 删除s字符串中开头、结尾处，位于 rm删除序列的字符 s.lstrip(rm) 删除s字符串中开头处，位于 rm删除序列的字符s.rstrip(rm) 删除s字符串中结尾处，位于 rm删除序列的字符 注意： 当rm为空时，默认删除空白符（包括’\\n’, ‘\\r’, ‘\\t’, ‘ ‘) 2.这里的rm删除序列是只要边（开头或结尾）上的字符在删除序列内，就删除掉。 yield关于Python中的yield yield返回的是一个生成器 生成器最大的却别是它并不返回一个真正的数组yield 则是这个神奇的东西，和return一样，他返回东西，但他返回的是一个生成器生成器是通过一个或多个yield表达式构成的函数，每一个生成器都是一个迭代器（但是迭代器不一定是生成器）。如果一个函数包含yield关键字，这个函数就会变为一个生成器。生成器并不会一次返回所有结果，而是每次遇到yield关键字后返回相应结果，并保留函数当前的运行状态，等待下一次的调用。","categories":[],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"我的第一篇博客","slug":"我的第一篇博客","date":"2017-07-09T09:03:52.102Z","updated":"2017-10-21T11:00:18.500Z","comments":true,"path":"2017/07/09/我的第一篇博客/","link":"","permalink":"http://yoursite.com/2017/07/09/我的第一篇博客/","excerpt":"日期: 2017-07-06 14:45:52正文:第一次用博客，写一篇文章记录一下。","text":"日期: 2017-07-06 14:45:52正文:第一次用博客，写一篇文章记录一下。 到今天，学习了以下的内容：1.Python3廖雪峰教程看到了函数式编程2.python的编码规范3.pythonic的典型实例4.学会了如何搭建自己的博客。5.Markdown的基本语法 虽然刚开始几天，但是收获可以说不少吧。Python虽然看了一遍，但是仅仅到达了解的地步，还没有完全掌握，这两天需要多练习Python代码。","categories":[],"tags":[{"name":"心得","slug":"心得","permalink":"http://yoursite.com/tags/心得/"}]},{"title":"python 自学笔记","slug":"python-自学笔记","date":"2017-07-09T09:03:52.082Z","updated":"2017-10-21T10:57:55.207Z","comments":true,"path":"2017/07/09/python-自学笔记/","link":"","permalink":"http://yoursite.com/2017/07/09/python-自学笔记/","excerpt":"日期: 2017-07-07 17:17:42tags: python对于单个字符的编码，Python 提供了ord()函数获取字符的整数表示，chr()函数把编码转换为对应的字符：","text":"日期: 2017-07-07 17:17:42tags: python对于单个字符的编码，Python 提供了ord()函数获取字符的整数表示，chr()函数把编码转换为对应的字符： &gt;&gt;&gt; ord(&apos;A&apos;) 65 &gt;&gt;&gt; ord(&apos;中&apos;) 20013 &gt;&gt;&gt; chr(66) &apos;B&apos; &gt;&gt;&gt; chr(25991) &apos;文&apos; 以 Unicode 表示的 str 通过 encode() 方法可以编码为指定的 bytes ，例如： &gt;&gt;&gt; &apos;ABC&apos;.encode(&apos;ascii&apos;) b&apos;ABC&apos; &gt;&gt;&gt; &apos;中文&apos;.encode(&apos;utf-8&apos;) b&apos;\\xe4\\xb8\\xad\\xe6\\x96\\x87&apos; &gt;&gt;&gt; b&apos;ABC&apos;.decode(&apos;ascii&apos;) &apos;ABC&apos; &gt;&gt;&gt; b&apos;\\xe4\\xb8\\xad\\xe6\\x96\\x87&apos;.decode(&apos;utf-8&apos;) &apos;中文&apos; 计算字符串长度： &gt;&gt;&gt; len(&apos;ABC&apos;) 3 保留小数: &gt;&gt;&gt; &apos;%2d-%02d&apos; % (3, 1) &apos; 3-01&apos; &gt;&gt;&gt; &apos;%.2f&apos; % 3.1415926 &apos;3.14&apos; 有些时候，字符串里面的 % 是一个普通字符怎么办？这个时候就需要转义，用 %% 来表示一个 % ： &gt;&gt;&gt; &apos;growth rate: %d %%&apos; % 7 &apos;growth rate: 7 %&apos; list列表用法： &gt;&gt;&gt; classmates = [&apos;Michael&apos;, &apos;Bob&apos;, &apos;Tracy&apos;] &gt;&gt;&gt; classmates [&apos;Michael&apos;, &apos;Bob&apos;, &apos;Tracy&apos;] &gt;&gt;&gt; classmates[0] &apos;Michael&apos; 获取最后一个元素： &gt;&gt;&gt; classmates[-1] &apos;Tracy&apos; 往 list 中追加元素到末尾： &gt;&gt;&gt; classmates.append(&apos;Adam&apos;) 把元素插入到指定的位置，比如索引号为 1 的位置： &gt;&gt;&gt; classmates.insert(1, &apos;Jack&apos;) 要删除指定位置的元素，用 pop(i) 方法，其中 i 是索引位置： &gt;&gt;&gt; classmates.pop(1) 要把某个元素替换成别的元素，可以直接赋值给对应的索引位置： &gt;&gt;&gt; classmates[1] = &apos;Sarah&apos; Python 的循环有两种，一种是 for...in 循环，依次把 list 或 tuple 中的每个元素迭代出来，看例子： names = [&apos;Michael&apos;, &apos;Bob&apos;, &apos;Tracy&apos;] for name in names: print(name) 执行这段代码，会依次打印 names 的每一个元素： Michael, Bob, Tracy sum = 0 for x in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]: sum = sum + x print(sum) sum = 0 for x in range(101): sum = sum + x print(sum) 第二种循环是 while 循环，只要条件满足，就不断循环，条件不满足时退出循环。 sum = 0 n = 99 while n &gt; 0: sum = sum + n n = n - 2 print(sum) 重复元素在 set 中自动被过滤： &gt;&gt;&gt; s = set([1, 1, 2, 2, 3, 3]) &gt;&gt;&gt; s {1, 2, 3} &gt;&gt;&gt; s.add(4) &gt;&gt;&gt; s {1, 2, 3, 4} 通过 remove(key) 方法可以删除元素： &gt;&gt;&gt; s.remove(4) &gt;&gt;&gt; s {1, 2, 3} set 可以看成数学意义上的无序和无重复元素的集合，因此，两个 set 可以做数学意义上的交集、并集等操作： &gt;&gt;&gt; s1 = set([1, 2, 3]) &gt;&gt;&gt; s2 = set([2, 3, 4]) &gt;&gt;&gt; s1 &amp; s2 {2, 3} &gt;&gt;&gt; s1 | s2 {1, 2, 3, 4} 而对于不可变对象，比如 str，对 str 进行操作呢： &gt;&gt;&gt; a = &apos;abc&apos; &gt;&gt;&gt; a.replace(&apos;a&apos;, &apos;A&apos;) &apos;Abc&apos; &gt;&gt;&gt; a &apos;abc&apos; &gt;&gt;&gt; max(2, 3, 1, -5) 3 &gt;&gt;&gt; int(&apos;123&apos;) 123 &gt;&gt;&gt; int(12.34) 12 math包里含有数学运算有：三角函数：cos,sin。。开平方sqrt() &gt;&gt;&gt; import math &gt;&gt;&gt; math.sqrt(2) 1.4142135623730951 def power(x, n): s = 1 while n &gt; 0: n = n - 1 s = s * x return s 对于这个修改后的 power(x, n) 函数，可以计算任意 n 次方： &gt;&gt;&gt; power(5, 2) 25 &gt;&gt;&gt; power(5, 3) 125 def enroll(name, gender, age=6, city=&apos;Beijing&apos;): print(&apos;name:&apos;, name) print(&apos;gender:&apos;, gender) print(&apos;age:&apos;, age) print(&apos;city:&apos;, city) 这样，大多数学生注册时不需要提供年龄和城市，只提供必须的两个参 数： &gt;&gt;&gt; enroll(&apos;Sarah&apos;, &apos;F&apos;) name: Sarah gender: F age: 6 city: Beijing def calc(numbers): sum = 0 for n in numbers: sum = sum + n * n return sum &gt;&gt;&gt; calc((1, 3, 5, 7)) 定义可变参数和定义一个 list 或 tuple 参数相比，仅仅在参数前面加了一个 * 号。 def calc(*numbers): sum = 0 for n in numbers: sum = sum + n * n return sum &gt;&gt;&gt; calc(1, 2) 5 &gt;&gt;&gt; nums = [1, 2, 3] &gt;&gt;&gt; calc(*nums) 14 def person(name, age, **kw): print(&apos;name:&apos;, name, &apos;age:&apos;, age, &apos;other:&apos;, kw) &gt;&gt;&gt; person(&apos;Michael&apos;, 30) name: Michael age: 30 other: {} &gt;&gt;&gt; person(&apos;Bob&apos;, 35, city=&apos;Beijing&apos;) name: Bob age: 35 other: {&apos;city&apos;: &apos;Beijing&apos;} 递归函数： def fact(n): if n==1: return 1 return n * fact(n - 1) &gt;&gt;&gt; fact(5) 120 函数的切片： &gt;&gt;&gt; L[0:3] [&apos;Michael&apos;, &apos;Sarah&apos;, &apos;Tracy&apos;] L[0:3] 表示，从索引 0 开始取，直到索引 3 为止，但不包括索引 3 。 &gt;&gt;&gt; (0, 1, 2, 3, 4, 5)[:3] (0, 1, 2) &gt;&gt;&gt; &apos;ABCDEFG&apos;[:3] &apos;ABC&apos; 前 10 个数，每两个取一个： &gt;&gt;&gt; L[:10:2] [0, 2, 4, 6, 8] Python异常处理 try…except…我们把可能发生错误的语句放在try模块里，用except来处理异常。except可以处理一个专门的异常，也可以处理一组圆括号中的异常，如果except后没有指定异常，则默认处理所有的异常。每一个try，都必须至少有一个except。当try语句块出现错误，便跳出try程序块，执行excepttry ….except…else 语句，当没有异常发生时，try和else中的语句将会被执行，而except不执行。12345678910a=10b=0try: c = b/ a print cexcept (IOError ,ZeroDivisionError),x: print xelse: print \"no error\"print \"done\" python if name == ‘main‘解析换句通俗的话讲，当你在当前文件运行一个文件时，__name__==__main__，则其后的代码会正常执行，但是当你在另一个文件import这个文件的时候，此时__name__！=__main__，则以下的代码将不会执行。至于他的作用，我简单的理解就是加入if __name__ == &quot;__main__&quot;后，它后面的代码在其它地方引用时，就不执行，从而方便了代码的重用。示例：add.py如下：1234567def add(x,y): return x+yif __name__ == \"__main__\"： print add(3,4) 当我在其它地方引用这个add.py时，就不执行print。","categories":[],"tags":[]},{"title":"python中lambda表达式学习","slug":"lambda表达式学习","date":"2017-07-09T09:03:52.033Z","updated":"2017-10-21T10:55:27.187Z","comments":true,"path":"2017/07/09/lambda表达式学习/","link":"","permalink":"http://yoursite.com/2017/07/09/lambda表达式学习/","excerpt":"date: 2017-07-07 18:09:14 tags: pythonlambda只是一个表达式，函数体比def简单很多。","text":"date: 2017-07-07 18:09:14 tags: pythonlambda只是一个表达式，函数体比def简单很多。lambda的主体是一个表达式，而不是一个代码块。仅仅能在lambda表达式中封装有限的逻辑进去。 lambda表达式是起到一个函数速写的作用。允许在代码内嵌入一个函数的定义。 如下例子：定义了一个lambda表达式，求三个数的和。 再看一个例子：用lambda表达式求n的阶乘。 lambda表达式也可以用在def函数中。如下例子： 这里定义了一个action函数，返回了一个lambda表达式。其中lambda表达式获取到了上层def作用域的变量名x的值。a是action函数的返回值，a(22)，即是调用了action返回的lambda表达式。这里也可以把def直接写成lambda形式。如下 看教程看到这一题答案发现原来有更简单的写法，用了lambda,当时不知道用法，然后百度后才明白 from functools import reduce def prod(L): return reduce(lambda x,y: x*y,L) print(&apos;3 * 5 * 7 * 9 =&apos;, prod([3, 5, 7, 9]))","categories":[],"tags":[]},{"title":"python的典型实例","slug":"python的典型实例","date":"2017-07-09T09:03:52.023Z","updated":"2017-10-21T10:56:27.578Z","comments":true,"path":"2017/07/09/python的典型实例/","link":"","permalink":"http://yoursite.com/2017/07/09/python的典型实例/","excerpt":"date: 2017-07-07 18:21:52 tags: pythonnonlocal关键字用来在函数或其他作用域中使用外层(非全局)变量。","text":"date: 2017-07-07 18:21:52 tags: pythonnonlocal关键字用来在函数或其他作用域中使用外层(非全局)变量。 不知道字符串转大写是upper()，转小写是lower() 忘记字符串也可以切片了 字符串的连接原来可以用加号+ 123456def normalize(name): return name[0].upper()+name[1:].lower()L1 = ['adam', 'LISA', 'barT']L2 = list(map(normalize, L1))print(L2) name[0].upper() 是首字母大写name[1:].lower() 从第二个字母开始全都小写 字符串转数的算法已经在示例中已经有了，也很好理解。转成浮点数的难点在于小数点两遍的数字处理方法不一样。我想肯定需要一个判断句，判断在小数点的左右，而采用不同的方法。同时，还要一个参数来记住小数点的位置。最终，又是参考各位大神，又是参照作者的答案。大概是懂了。 作者的答案:1234567891011121314151617181920212223242526272829303132from functools import reduceCHAR_TO_FLOAT = &#123; '0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '.': -1 &#125;def str2float(s): nums = map(lambda ch: CHAR_TO_FLOAT[ch], s) point = 0def to_float(f, n): nonlocal point if n == -1: point = 1 return f if point == 0: return f * 10 + n else: point = point * 10 return f + n / point return reduce(to_float, nums, 0.0) print(str2float('0')) print(str2float('123.456')) print(str2float('123.45600')) print(str2float('0.1234')) 由于to_float传入的数据都是数而不是字符，因此CHAR_TO_FLOAT里面定义.为0-9以外的数，加以区分。if n == -1:用来判断是否已经到小数点的位置，如果到了则改变point的值，point可以说是记录了当前小数点的位置，默认为0。然后根据point值来判断小数点的位置，以确定使用哪个转换算法。return reduce(to_float,nums,0.0)中有一项是0.0，是为了转换整数字符为浮点数。如果不添加0.0，则CHAR_TO_FLOAT里的value都要改成浮点数的形式，key值不用改，小数点对应的数值也可以不改。 筛选出字符串类型并展示：123456789101112L1=['hello','world',18,'apple',None]L2=[]n=1for s in L1: if isinstance(s,str)==1: L2.append(s.lower()) else: print('the number of non str is %d ' %(n)) n=n+1 print(L2)L2=[s.lower() for s in L1 if isinstance(s,str)==1]print(L2) 斐波拉契数列12345678 def fib(max): n, a, b = 0, 0, 1 while n &lt; max: print(b) a, b = b, a + b n = n + 1 return 'done'上面的函数可以输出斐波那契数列的前 N 个数：&gt;&gt;&gt; fib(6) 杨辉三角12345678910111213141516171819202122def triangles(): j = 0 L1 = [] L2 = [] S1 = 0 while j &lt; 10: s = 0 for i in L1: S1 = s + i s = i #記錄上個循環i的值 L2.append(S1) L2.append(1) yield L2 #生成器 返回L2 list 列表的值 L1 = L2[:] #將L1指向L2 變成上一次循環的list L2 = [] #L2保存的是當次循環的list 初始化她 j = j + 1n = 0for x in triangles(): print(x) n = n + 1 if n == 10: break 滤掉非回数回数是指从左向右读和从右向左读都是一样的数，例如 12321 ， 909 。请利用 filter() 滤掉非回数1234def i(n): return str(n) == str(n)[::-1]output = filter(i, range(1, 10000))print(list(output)) 把一个序列中的空字符串删掉1234def not_empty(s): return s and s.strip()list(filter(not_empty, ['A', '', 'B', None, 'C', ' ']))# 结果: ['A', 'B', 'C'] 删掉偶数，只保留奇数1234def is_odd(n): return n % 2 == 1list(filter(is_odd, [1, 2, 4, 5, 6, 9, 10, 15]))# 结果: [1, 5, 9, 15] 将一个16进制的数转换为十进制：123def int2(x, base=16): return int(x, base)print(int2('12345')) 排序假设我们用一组 tuple 表示学生名字和成绩：L = [(‘Bob’, 75), (‘Adam’, 92), (‘Bart’, 66), (‘Lisa’, 88)] 请用 sorted() 对上述列表分别按成绩从高到低排序：12345L = [('Bob', 75), ('Adam', 92), ('Bart', 66), ('Lisa', 88)]def by_name(t): return t[1]L2 = sorted(L, key=by_name, reverse = True)print(L2)","categories":[],"tags":[]}]}